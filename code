#!/usr/bin/env python
# coding: utf-8



get_ipython().system('pip install --upgrade tensorflow')
get_ipython().system('pip install --upgrade keras')




import os
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import tensorflow as tf
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing import image




dataset_path = r'C:\Users\chait\Downloads\archive\animals\animals'
if os.path.exists(dataset_path):
    print("Path exists.")
    print("Directory contents:", os.listdir(dataset_path))
else:
    print("Path does not exist.")
    exit()




# Image Data Generator for training
train_datagen = ImageDataGenerator(
    rescale=1./255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    validation_split=0.2  # Splitting the dataset into training and validation
)





# Creating training data generator
training_set = train_datagen.flow_from_directory(
    dataset_path,
    target_size=(64, 64),
    batch_size=32,
    class_mode='categorical',  # Change to 'categorical' for multi-class
    subset='training'
)





# Creating validation data generator
validation_set = train_datagen.flow_from_directory(
    dataset_path,
    target_size=(64, 64),
    batch_size=32,
    class_mode='categorical',  # Change to 'categorical' for multi-class
    subset='validation'
)
print("Training and validation sets created successfully.")




# Initialization of CNN
cnn = tf.keras.models.Sequential()





# First Convolutional Layer
cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))





# Pooling
cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))





# Adding a second Convolutional layer
cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))





# Adding a second pooling layer
cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))



# Flattening
cnn.add(tf.keras.layers.Flatten())




# Full connection
cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))




# Output layer (use softmax for multi-class classification)
cnn.add(tf.keras.layers.Dense(units=len(training_set.class_indices), activation='softmax'))





# Compiling the CNN
cnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])





# Training the CNN on the training set and evaluating it on the validation set
history = cnn.fit(x=training_set, validation_data=validation_set, epochs=50)




# Save the model for future use
cnn.save('species_classifier_model.h5')




# Function to load and preprocess the test image
def preprocess_image(image_path):
    test_image = image.load_img(image_path, target_size=(64, 64))
    test_image = image.img_to_array(test_image)
    test_image = np.expand_dims(test_image, axis=0)
    return test_image




# Predict the result
import numpy as np
test_image_path = r"C:\Users\chait\Downloads\archive\animals\animals\zebra\6eebb7baff.jpg"
test_image = preprocess_image(test_image_path)




# Predict the class
result = cnn.predict(test_image)





# Get the class labels
class_labels = {v: k for k, v in training_set.class_indices.items()}



# Determine the prediction
prediction = class_labels[np.argmax(result)]

print(f'Prediction: {prediction}')


